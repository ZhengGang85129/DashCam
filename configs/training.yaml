trainer_name: baseline_trainer  #single
batch_size: 10
decay_coefficient: 30
resume: False # If True, the model will load parameters from `check_point_path`
optim_resume: False # If True, the optimizer will load saved state from `optim_check_point_path` 
optimizer:
  name: adamw
  weight_decay: 0.005
  differential_lr:
    fc: 1e-3
    layer4: 1.0e-4
    layer3: 5.0e-5
    layer2: 2.0e-5

model_dir: test_on_unfreezing_strategy # will store the trained checkpoint under this folder
monitor_dir: test_on_unfreezing_strategy-monitor # will store the metric points under this. Currently, this will be overwritten by a new training process.
monitor_overwrite: True
check_point_path: #valid only if resume is True
optim_check_point_path: #valid only if optim_resume is True
unfreezing:
  schedule:
  - epoch: 0
    layers_to_unfreeze: ["fc"]
  - epoch: 5
    layers_to_unfreeze: ["layer4"]
  - epoch: 15
    layers_to_unfreeze: ["layer3"]
  - epoch: 20
    layers_to_unfreeze: ["layer2"]
  freeze_bn: true
early_stopping:
  delta: 0.001
  patience: 5